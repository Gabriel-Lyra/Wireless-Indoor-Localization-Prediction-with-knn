1. Nothing - inicialmente testaremos a acuracia do modelo com k = 3 e training size de 70%, medidas comumente adotadas para esté tipo de algoritmo. Os outros hyperparametros serão os default do sklearn.
Desta forma obtivemos uma acuracia de 99,36%, um resultado já bastante alto.

2. hyperparameter tuning + cross validation - nessa etepa testaremos os hyperparametros ideais e eliminaremos incertezas com relação a quais "pedaços" do dataset foram escolhidos durante o primeiro teste.

lembrando que no primeiro teste os seguintes hyperparametros foram utilizados: {k=3, leaf_size = default = 30, weights default = ’uniform’ e algorithm = default=’auto’}

os seguintes parametros foram testados no GridSearch:
k_range = range(1, 31)
leaf_range = 2 ** np.arange(10)  ---> gera o seguinte resultado: array([  1,   2,   4,   8,  16,  32,  64, 128, 256, 512])
weight_options = ['uniform', 'distance']
algorithm_options = ['ball_tree', 'kd_tree', 'brute']

no final, os hyperparametros escolhidos são o seguintes: {k = 4, leaf_size = 1, weights = 'uniform', algorithm = 'ball_tree'}

e obtivemos uma acuracia de 99,21%, uma redução se comparado ao teste inicial. Seria dificil descrever exatamente o porque deste resultado, porém a resposta possivelmente se encontra no fato que o resultado é
obtido a partir da pontuação média de validação cruzada do best_estimator, de forma que não necessariamente a acuracia abaixou, mas na realidade encontramos uma acuracia media, uma representação geral da acuracia do nosso algoritmo.

3. hyperparameter tuning + cross validation + Normalising - Esta etapa normalmente é feita logo após ler o dataset, com o objetivo de evitar uma escolha erronia do vizinho mais proximo. 
(mostrar exemplo: https://stats.stackexchange.com/questions/287425/why-do-you-need-to-scale-data-in-knn)

Surpreendentemente conseguimos um resultado perfeito, com 100% de acuracia. Apesar de incomum (ao ponto de ser um indicação de erro por parte do programador) no mundo dos algoritmos de predição, este resultado faz sentido se 
considerarmos o dataset no qual estamos trabalhando: medidas de wi=fi em salas diferentes. Um problema no qual deve existir uma formula que descreve perfeitamente os resultados, afinal uma sala possui tamanha definido e que não muda.

4. bagging + hyperparameter tuning + cross validation + Normalising - o proximo passo seria utilizar do metodo de bagging, para 